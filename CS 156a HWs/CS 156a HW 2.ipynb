{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyND8ODWZjCE5pJsESyvxxvS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Question 1 - 2##"],"metadata":{"id":"MugV3mOdHjqV"}},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"PeRB1V0vHhMb","executionInfo":{"status":"ok","timestamp":1696564189683,"user_tz":420,"elapsed":14496,"user":{"displayName":"Alfin Hou","userId":"02529736084419145803"}},"outputId":"19cffc76-727a-4921-8210-1465944dc41f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average values for v_1, v_rand, v_min are: 0.49985700000000005 0.4993109999999999 0.03776\n"]}],"source":["# Imports\n","import numpy as np\n","\n","# Prepare to record the result:\n","min_arr = []\n","rand_arr = []\n","fst_arr = []\n","\n","# Run experiments\n","for _ in range(100000):\n","  # Create Matrix to store coin flip results\n","  coin_mat = np.random.choice([0, 1], (1000,10))\n","\n","  coin_frac = np.sum(coin_mat, axis = 1)/10\n","\n","  v_min = np.min(coin_frac)\n","  v_rand = coin_frac[np.random.randint(0, 1000)]\n","  v_1 = coin_frac[0]\n","\n","  min_arr.append(v_min)\n","  rand_arr.append(v_rand)\n","  fst_arr.append(v_1)\n","\n","print(\"Average values for v_1, v_rand, v_min are:\",\n","      np.mean(fst_arr), np.mean(rand_arr), np.mean(min_arr))"]},{"cell_type":"markdown","source":["As we can see from the simulation above, the average value of $\\nu_{min}$ is cloest to $0.01$.   \n","Hence, I choose $[b]$ for Question $1$.  \n","$c_1, c_{rand}$ satisfies the Hoeffding Inequality because both of them can be considered as an experiment of flipping a single coin (as each coin flip is independent), which is performed $100000$ times. Hence, for them, $\\mathbb{P}(|\\nu-μ|>ϵ)$ can be effectively bounded by the Hoeffding Inequality.  \n","However, $c_{min}$ in this case, represents the worst case senario. Since we are considering the minumum of $1000$ coins, we have to consider the union of all of their probabilities. Hence, we can only use the \"multiple bin\" version of the Hoeffding Inequality to bound the probability of $|\\nu - \\mu|>ϵ$ in this case.\n","Hence, I choose $[d]$ for Question $2$."],"metadata":{"id":"nQ9x48NYMtH-"}},{"cell_type":"markdown","source":["##Question 3 - 4##\n","For question $3$, $h$ is going to make an error in the following situation:\n","  - $A$: $h(\\mathrm{x})$ approximates $f(\\mathrm{x})$ correctly, but $y\\neq f(\\mathrm{x})$\n","  - $B$: $h(\\mathrm{x})$ approximates $f(\\mathrm{x})$ incorrectly, but $y = f(\\mathrm{x})$\n","\n","Here, we have:\n","$$\\mathbb{P}(A) = (1-\\mu)(1-\\lambda), \\mathbb{P}(B) = \\mu \\lambda$$\n","Here $\\mathbb{P}(A\\cap B) = 0$ because the approximation of $h$ can't be both correct and incorrect. Hence, the probability of making an error is as follows:\n","$$\\mathbb{P}(Error) = \\mathbb{P}(A) + \\mathbb{P}(B) + 0 = (1-\\mu)(1-\\lambda) + \\mu \\lambda$$\n","Therefore, I choose $[e]$ for Question $3$.  \n","For question $4$, consider the previous expression of $\\mathbb{P}(Error)$,when $\\mu = \\frac{1}{2}$, we will have the following expression:\n","$$\\mathbb{P}(Error) = (1-\\frac{1}{2})(1-\\lambda) + \\frac{1}{2} \\lambda = \\frac{1}{2}(1 - λ) + \\frac{1}{2}λ = \\frac{1}{2}$$\n","In this case, the probability for $h$ to make an error is $\\frac{1}{2}$, regardless of what $\\lambda$ is.  \n","Hence, I choose $[b]$ for Question $4$.\n"],"metadata":{"id":"7kyt4_6lQOtF"}},{"cell_type":"markdown","source":["##Question 5 - 6##"],"metadata":{"id":"zrTkOeezWWaI"}},{"cell_type":"code","source":["# Store E_in and E_out in different experiments\n","in_arr = []\n","out_arr = []\n","N = 100\n","\n","# Experiment (1000 runs)\n","for _ in range(1000):\n","  # Generate lines and samples\n","  point_head = np.random.uniform(-1, 1, 2)\n","  point_tail = np.random.uniform(-1, 1, 2)\n","  a = point_head[1] - point_tail[1]\n","  b = point_tail[0] - point_head[0]\n","  c = a * point_head[0] + b * point_head[1]\n","  sample_points = np.random.uniform(-1, 1, (N, 2))\n","  dummy_points = np.c_[sample_points[:, 0], sample_points[:, 1], np.ones(N)]\n","  coeffs = np.array([a, b, c])\n","\n","  # Create correct classification\n","  correct_classification = np.sign(np.dot(dummy_points, coeffs))\n","\n","  # Linear regression\n","  g_coeff = np.linalg.lstsq(dummy_points, correct_classification, rcond = None)[0]\n","\n","  # Compute in-sample performance\n","  approx_result = np.sign(np.dot(dummy_points, g_coeff))\n","  E_in = np.sum(approx_result != correct_classification)/N\n","  in_arr.append(E_in)\n","\n","  # Compute Out-of-sample performance\n","  new_points = np.random.uniform(-1, 1, (1000, 2))\n","  new_dummy = np.c_[new_points[:, 0], new_points[:, 1], np.ones(1000)]\n","  actual_result = np.sign(np.dot(new_dummy, coeffs))\n","  g_result = np.sign(np.dot(new_dummy, g_coeff))\n","  E_out = np.sum(g_result != actual_result)/1000\n","  out_arr.append(E_out)\n","\n","print(\"Average E_in when N = \", N, \":\",np.mean(in_arr))\n","print(\"Average E_out when N = \", N, \":\",np.mean(out_arr))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Yu3XHZNyQNsw","executionInfo":{"status":"ok","timestamp":1696564189684,"user_tz":420,"elapsed":77,"user":{"displayName":"Alfin Hou","userId":"02529736084419145803"}},"outputId":"59b31fc1-d320-4008-bfd4-7dce73c56164"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Average E_in when N =  100 : 0.03937\n","Average E_out when N =  100 : 0.048192000000000006\n"]}]},{"cell_type":"markdown","source":["Based on the simulation result, I choose $[c]$ for Question $5$, and $[c]$ for Question $6$."],"metadata":{"id":"q-UhbSc7eFza"}},{"cell_type":"markdown","source":["##Question 7##"],"metadata":{"id":"ArYtXSlQi_z9"}},{"cell_type":"code","source":["# Set N = 10\n","N = 10\n","num_iter = []\n","for _ in range(1000):\n","  # Generate lines and samples\n","  point_head = np.random.uniform(-1, 1, 2)\n","  point_tail = np.random.uniform(-1, 1, 2)\n","  a = point_head[1] - point_tail[1]\n","  b = point_tail[0] - point_head[0]\n","  c = a * point_head[0] + b * point_head[1]\n","  sample_points = np.random.uniform(-1, 1, (N, 2))\n","  dummy_points = np.c_[sample_points[:, 0], sample_points[:, 1], np.ones(N)]\n","  coeffs = np.array([a, b, c])\n","\n","  # Create correct classification\n","  correct_classification = np.sign(np.dot(dummy_points, coeffs))\n","\n","  # Linear regression\n","  g_coeff = np.linalg.lstsq(dummy_points, correct_classification, rcond = None)[0]\n","\n","  # Start PLA\n","  w = g_coeff\n","  iter = 0\n","  flag = False\n","  while flag == False:\n","    iter += 1\n","    # Perceptron\n","    h_x = np.sign(np.dot(dummy_points, w))\n","\n","    # Check for misclassification\n","    mis_idx = []\n","    for i in range(N):\n","      if h_x[i] != correct_classification[i]:\n","        mis_idx.append(i)\n","    # Exit the run if all points are correctly classified\n","    if len(mis_idx) == 0:\n","      flag = True\n","    else:\n","      idx = np.random.choice(mis_idx)\n","      w += correct_classification[idx] * dummy_points[idx]\n","  num_iter.append(iter)\n","\n","print(\"The average number of iterations it takes to converge is:\", np.mean(num_iter))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"87gvpQZxjbJB","executionInfo":{"status":"ok","timestamp":1696564189907,"user_tz":420,"elapsed":291,"user":{"displayName":"Alfin Hou","userId":"02529736084419145803"}},"outputId":"6135b4a2-e321-4a19-c920-f6cd7f80d528"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["The average number of iterations it takes to converge is: 6.679\n"]}]},{"cell_type":"markdown","source":["Based on the simulation result, I choose $[a]$ for Question $7$."],"metadata":{"id":"dxIsvtV8kNCY"}},{"cell_type":"markdown","source":["##Question 8 - 9##\n"],"metadata":{"id":"JGRhSZsM32M4"}},{"cell_type":"code","source":["# Define the target function\n","target_f = lambda x: np.sign(x[0] ** 2 + x[1] ** 2 - 0.6)\n","\n","# Stores E_in in different experiments\n","in_arr = []\n","\n","# Stores the coefficients of candidate functions in the question\n","prob_arr = np.zeros(5)\n","coeff_arr = np.array([[-1, -0.05, 0.08, 0.13, 1.5, 1.5],\n","                      [-1, -0.05, 0.08, 0.13, 1.5, 15],\n","                      [-1, -0.05, 0.08, 0.13, 15, 1.5],\n","                      [-1, -1.5, 0.08, 0.13, 0.05, 0.05],\n","                      [-1, -0.05, 0.08, 1.5, 0.15, 0.15]])\n","# Perform experiments\n","for _ in range(1000):\n","  sample_points = np.random.uniform(-1, 1, (1000, 2))\n","  correct_output = np.array([target_f(sample_points[i]) for i in range(1000)])\n","  noised_index = np.random.choice(range(1000), 100, replace = False)\n","  noised_output = np.array([(-correct_output[i] if i in noised_index else correct_output[i]) for i in range(1000)])\n","\n","  training_set = np.c_[np.ones(1000), sample_points[:,0], sample_points[:,1]]\n","  reg_w = np.linalg.lstsq(training_set, noised_output, rcond = None)[0]\n","  reg_output = np.sign(np.dot(training_set, reg_w))\n","\n","  E_in = np.sum(reg_output != noised_output)/1000\n","  in_arr.append(E_in)\n","\n","  # Non-linear transform\n","  transferred_set = np.c_[np.ones(1000), sample_points[:,0],\n","                          sample_points[:,1], sample_points[:,0] * sample_points[:,1],\n","                          sample_points[:,0] ** 2, sample_points[:,1] ** 2]\n","\n","  reg_w_tilde = np.linalg.lstsq(transferred_set, noised_output, rcond = None)[0]\n","  nonlinear_result = np.sign(np.dot(transferred_set, reg_w_tilde))\n","\n","  # Compare results\n","  for j in range(0, 5):\n","    result = np.sign(np.dot(transferred_set, coeff_arr[j]))\n","    prob_arr[j] += np.mean(nonlinear_result == result)\n","\n","\n","\n","print(\"Average E_in:\", np.mean(in_arr))\n","print(\"Average Probability for each set of coefficients:\", prob_arr/1000)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"T56fDxzR4cLU","executionInfo":{"status":"ok","timestamp":1696564197011,"user_tz":420,"elapsed":7112,"user":{"displayName":"Alfin Hou","userId":"02529736084419145803"}},"outputId":"8f217a86-b1a9-4745-e611-686a45574d33"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Average E_in: 0.5046430000000001\n","Average Probability for each set of coefficients: [0.961738 0.663712 0.663259 0.630723 0.559973]\n"]}]},{"cell_type":"markdown","source":["Based on the simulation result, I choose $[d]$ for Question $8$, $[a]$ for Question $9$."],"metadata":{"id":"JMHeSm159yZS"}},{"cell_type":"markdown","source":["##Question 10##"],"metadata":{"id":"E-v2e3_9EFHD"}},{"cell_type":"code","source":["# Prepare to store E_out\n","out_arr = []\n","\n","# Perform 1000 experiments\n","for _ in range(1000):\n","  sample_points = np.random.uniform(-1, 1, (1000, 2))\n","  correct_output = np.array([target_f(sample_points[i]) for i in range(1000)])\n","  noised_index = np.random.choice(range(1000), 100, replace = False)\n","  noised_output = np.array([(-correct_output[i] if i in noised_index else correct_output[i]) for i in range(1000)])\n","  testing_set = np.c_[np.ones(1000), sample_points[:,0],\n","                          sample_points[:,1], sample_points[:,0] * sample_points[:,1],\n","                          sample_points[:,0] ** 2, sample_points[:,1] ** 2]\n","  reg_out = np.sign(np.dot(testing_set, reg_w_tilde))\n","  E_out = np.sum(reg_out != noised_output)/1000\n","  out_arr.append(E_out)\n","\n","print(\"Average out-of-sample performance:\", np.mean(out_arr))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"e7Rvykq0EITN","executionInfo":{"status":"ok","timestamp":1696564206226,"user_tz":420,"elapsed":9298,"user":{"displayName":"Alfin Hou","userId":"02529736084419145803"}},"outputId":"9a3b614d-d7de-4d53-903d-c5619e50817f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Average out-of-sample performance: 0.120999\n"]}]},{"cell_type":"markdown","source":["Based on the simulation result, I choose $[b]$ for Question $10$."],"metadata":{"id":"SPjilJs5G45q"}}]}